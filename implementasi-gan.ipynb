{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7549663,"sourceType":"datasetVersion","datasetId":4396959}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Persiapan Library dan Dataset\nKita pakai PyTorch untuk implementasi. Dataset MNIST (gambar digit 0-9 hitam putih 28x28 pixel).","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# Hyperparameter\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlr = 0.0002  # Learning rate\nbatch_size = 128\nimage_size = 28 * 28  # Untuk MNIST, flatten jadi 784\nhidden_size = 256\nlatent_size = 100  # Ukuran noise input untuk Generator\nnum_epochs = 50  # Bisa tambah kalau mau hasil lebih baik\nbeta1 = 0.5  # Untuk Adam optimizer\n\n# Transform dataset\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])  # Normalize ke [-1,1] untuk tanh activation\n])\n\n# Load MNIST dataset\ndataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transform, download=True)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Buat folder untuk simpan gambar dan model\nos.makedirs(\"generated_images\", exist_ok=True)\nos.makedirs(\"models\", exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T01:23:38.019287Z","iopub.execute_input":"2025-09-02T01:23:38.019962Z","iopub.status.idle":"2025-09-02T01:23:51.890248Z","shell.execute_reply.started":"2025-09-02T01:23:38.019931Z","shell.execute_reply":"2025-09-02T01:23:51.889235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Arsitektur Generator\nGenerator: Input noise (latent_size=100), output gambar flatten (784). Pakai fully connected layers.","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size * 2),\n            nn.ReLU(),\n            nn.Linear(hidden_size * 2, hidden_size * 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size * 4, image_size),\n            nn.Tanh()  # Output [-1,1]\n        )\n    \n    def forward(self, z):\n        return self.model(z).view(-1, 1, 28, 28)  # Reshape ke gambar 1x28x28\n\n# Inisialisasi Generator\ngenerator = Generator().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T01:24:32.722653Z","iopub.execute_input":"2025-09-02T01:24:32.723088Z","iopub.status.idle":"2025-09-02T01:24:32.749891Z","shell.execute_reply.started":"2025-09-02T01:24:32.723062Z","shell.execute_reply":"2025-09-02T01:24:32.748850Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Arsitektur Discriminator\nDiscriminator: Input gambar (flatten 784), output probabilitas (0-1) apakah real atau fake.","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(image_size, hidden_size * 4),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_size * 4, hidden_size * 2),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_size * 2, hidden_size),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_size, 1),\n            nn.Sigmoid()  # Output probabilitas\n        )\n    \n    def forward(self, img):\n        return self.model(img.view(-1, image_size))  # Flatten input\n\n# Inisialisasi Discriminator\ndiscriminator = Discriminator().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T01:25:14.057202Z","iopub.execute_input":"2025-09-02T01:25:14.057716Z","iopub.status.idle":"2025-09-02T01:25:14.084084Z","shell.execute_reply.started":"2025-09-02T01:25:14.057690Z","shell.execute_reply":"2025-09-02T01:25:14.083071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training GAN\nLoss: Binary Cross Entropy. Optimizer: Adam.\nKita train Discriminator dulu (dengan real dan fake), lalu Generator (dengan feedback dari Discriminator).","metadata":{}},{"cell_type":"code","source":"# Loss dan Optimizer\ncriterion = nn.BCELoss()\noptimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n\n# List untuk track loss\ng_losses = []\nd_losses = []\n\n# Training loop\nfor epoch in range(num_epochs):\n    for i, (real_images, _) in enumerate(dataloader):\n        real_images = real_images.to(device)\n        batch_size_real = real_images.size(0)\n        \n        # Train Discriminator\n        optimizerD.zero_grad()\n        \n        # Real images\n        real_labels = torch.ones(batch_size_real, 1).to(device)\n        output_real = discriminator(real_images)\n        lossD_real = criterion(output_real, real_labels)\n        \n        # Fake images\n        z = torch.randn(batch_size_real, latent_size).to(device)  # Noise\n        fake_images = generator(z)\n        fake_labels = torch.zeros(batch_size_real, 1).to(device)\n        output_fake = discriminator(fake_images.detach())\n        lossD_fake = criterion(output_fake, fake_labels)\n        \n        # Total D loss\n        lossD = lossD_real + lossD_fake\n        lossD.backward()\n        optimizerD.step()\n        \n        # Train Generator\n        optimizerG.zero_grad()\n        output_fake_forG = discriminator(fake_images)  # Re-use fake images\n        lossG = criterion(output_fake_forG, real_labels)  # Ingin D anggap fake sebagai real\n        lossG.backward()\n        optimizerG.step()\n    \n    # Simpan loss\n    g_losses.append(lossG.item())\n    d_losses.append(lossD.item())\n    \n    # Generate dan simpan gambar tiap 10 epoch\n    if (epoch + 1) % 10 == 0 or epoch == 0:\n        with torch.no_grad():\n            fake = generator(torch.randn(64, latent_size).to(device)).detach().cpu()\n            grid = vutils.make_grid(fake, padding=2, normalize=True)\n            plt.imshow(np.transpose(grid, (1,2,0)))\n            plt.title(f\"Epoch {epoch+1}\")\n            plt.show()\n            vutils.save_image(grid, f\"generated_images/epoch_{epoch+1}.png\")\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}\")\n\n# Simpan model\ntorch.save(generator.state_dict(), \"models/generator.pth\")\ntorch.save(discriminator.state_dict(), \"models/discriminator.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T01:25:54.621478Z","iopub.execute_input":"2025-09-02T01:25:54.621839Z","iopub.status.idle":"2025-09-02T01:28:27.054562Z","shell.execute_reply.started":"2025-09-02T01:25:54.621809Z","shell.execute_reply":"2025-09-02T01:28:27.053036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualisasi Loss Selama Training","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.plot(g_losses, label=\"Generator Loss\")\nplt.plot(d_losses, label=\"Discriminator Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"GAN Loss During Training\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Perbedaan Hasil Antara Epoch Awal dan Akhir\nDi epoch awal (misal epoch 1-10), gambar hasil generator biasanya berupa noise acak atau bentuk samar-samar, karena model belum belajar pola digit MNIST dengan baik. Loss G tinggi, D mudah bedain fake.\n\nDi epoch akhir (misal epoch 40-50), gambar lebih jelas menyerupai digit asli (0-9), meski mungkin masih ada artifact. Loss stabil, menandakan equilibrium antara G dan D. Ini menunjukkan GAN berhasil belajar distribusi data MNIST.","metadata":{}}]}